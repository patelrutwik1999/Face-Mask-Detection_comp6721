{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVl2LhOMGHQh"
      },
      "source": [
        "#All the required files are imported here\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.transforms import ToPILImage, Compose, ToTensor, Resize, Normalize\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1PjKCLbHXvd"
      },
      "source": [
        "#References\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x53a-rXXHNLg",
        "outputId": "fd9a92ca-8043-4ac4-84ca-faabc3c3a1cc"
      },
      "source": [
        "#Setting the path up for the dataset. Dataset is in Goole Drive\n",
        "drive.mount('/content/drive')\n",
        "dir_path = \"/content/drive/My Drive/Face Mask Detection/Datasets\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAj2iWcQHax5",
        "outputId": "faec72b9-c53a-4fae-d98e-fa6c395c8812"
      },
      "source": [
        "#Data to be classified into this four categories\n",
        "classes = os.listdir(dir_path)\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['without_mask', 'surgical_mask', 'cloth_mask', 'ffp2_mask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_wubfuUHss0",
        "outputId": "1ae9ecf1-ea7a-4bb6-cf51-3d9d38f855c9"
      },
      "source": [
        "#Here, we will take labels and then zip them with respective classes\n",
        "label = [i for i in range(len(classes))]\n",
        "print(label)\n",
        "\n",
        "label_dict = dict(zip(classes,label))\n",
        "print(label_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3]\n",
            "{'without_mask': 0, 'surgical_mask': 1, 'cloth_mask': 2, 'ffp2_mask': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZzy8Bp0IImm",
        "outputId": "8234d8c5-a45e-4b27-c336-e43e2519222a"
      },
      "source": [
        "#Retreiving the data from the specified path and then appending the data and its label into numpy array.\n",
        "data = []\n",
        "labels = []\n",
        "for label in tqdm(classes):\n",
        "  data_path = os.path.join(dir_path, label)#Category Path(Path to Surgical Mask)\n",
        "  print(data_path)\n",
        "  image_names = os.listdir(data_path) #Images\n",
        "  print(image_names)\n",
        "  for image in tqdm(image_names): #YTube - TQDM\n",
        "    image_path = os.path.join(data_path, image)\n",
        "    images = cv2.imread(image_path) \n",
        "    try:\n",
        "      imag = cv2.cvtColor(images, cv2.COLOR_RGB2GRAY)\n",
        "      img = cv2.resize(imag, (100,100))\n",
        "      \n",
        "      data.append((img, label_dict[label]))\n",
        "      #print(data)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      \n",
        "np.save('data',data)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Face Mask Detection/Datasets/without_mask\n",
            "['67.jpg', '220.jpg', '92.jpg', '197.jpg', '154.jpg', '195.jpg', '105.jpg', '30.jpg', '170.jpg', '74.jpg', '280.jpg', '228.jpg', '109.jpg', '237.jpg', '17.jpg', '187.jpg', '271.jpg', '31.jpg', '52.jpg', '87.jpg', '232.jpg', '231.jpg', '264.jpg', '207.jpg', '225.jpg', '328.jpg', '234.jpg', '174.jpg', '258.jpg', '117.jpg', '211.jpg', '33.jpg', '239.jpg', '131.jpg', '123.jpg', '198.jpg', '339.jpg', '37.jpg', '135.jpg', '259.jpg', '163.jpg', '255.jpg', '66.jpg', '86.jpg', '65.jpg', '22.jpg', '80.jpg', '221.jpg', '303.jpg', '227.jpg', '204.jpg', '324.jpg', '242.jpg', '249.jpg', '265.jpg', '267.jpg', '58.jpg', '34.jpg', '334.jpg', '146.jpg', '285.jpg', '266.jpg', '252.jpg', '336.jpg', '166.jpg', '270.jpg', '1.jpg', '152.jpg', '55.jpg', '84.jpg', '216.jpg', '49.jpg', '300.jpg', '295.jpg', '112.jpg', '243.jpg', '201.jpg', '141.jpg', '325.jpg', '191.jpg', '212.jpg', '11.jpg', '276.jpg', '88.jpg', '326.jpg', '36.jpg', '119.jpg', '69.jpg', '188.jpg', '281.jpg', '323.jpg', '297.jpg', '180.jpg', '186.jpg', '6.jpg', '129.jpg', '254.jpg', '161.jpg', '115.jpg', '162.jpg', '318.jpg', '59.jpg', '215.jpg', '290.jpg', '208.jpg', '262.jpg', '73.jpg', '286.jpg', '27.jpg', '179.jpg', '196.jpg', '56.jpg', '155.jpg', '153.jpg', '169.jpg', '15.jpg', '284.jpg', '136.jpg', '151.jpg', '13.jpg', '89.jpg', '62.jpg', '311.jpg', '149.jpg', '77.jpg', '250.jpg', '138.jpg', '287.jpg', '347.jpg', '218.jpg', '203.jpg', '24.jpg', '108.jpg', '173.jpg', '206.jpg', '93.jpg', '229.jpg', '100.jpg', '331.jpg', '94.jpg', '294.jpg', '344.jpg', '29.jpg', '10.jpg', '14.jpg', '302.jpg', '335.jpg', '178.jpg', '26.jpg', '176.jpg', '145.jpg', '340.jpg', '230.jpg', '184.jpg', '28.jpg', '348.jpg', '114.jpg', '282.jpg', '61.jpg', '213.jpg', '315.jpg', '337.jpg', '43.jpg', '142.jpg', '193.jpg', '233.jpg', '244.jpg', '322.jpg', '0.jpg', '106.jpg', '306.jpg', '223.jpg', '3.jpg', '57.jpg', '18.jpg', '90.jpg', '308.jpg', '47.jpg', '118.jpg', '157.jpg', '226.jpg', '321.jpg', '293.jpg', '46.jpg', '158.jpg', '217.jpg', '185.jpg', '32.jpg', '16.jpg', '172.jpg', '164.jpg', '124.jpg', '12.jpg', '143.jpg', '317.jpg', '140.jpg', '125.jpg', '253.jpg', '7.jpg', '175.jpg', '159.jpg', '110.jpg', '120.jpg', '116.jpg', '292.jpg', '39.jpg', '148.jpg', '222.jpg', '307.jpg', '310.jpg', '194.jpg', '269.jpg', '45.jpg', '338.jpg', '4.jpg', '332.jpg', '260.jpg', '139.jpg', '330.jpg', '83.jpg', '53.jpg', '171.jpg', '214.jpg', '183.jpg', '70.jpg', '9.jpg', '246.jpg', '247.jpg', '224.jpg', '19.jpg', '309.jpg', '156.jpg', '54.jpg', '20.jpg', '64.jpg', '130.jpg', '51.jpg', '101.jpg', '241.jpg', '42.jpg', '122.jpg', '298.jpg', '341.jpg', '44.jpg', '263.jpg', '132.jpg', '104.jpg', '210.jpg', '301.jpg', '40.jpg', '291.jpg', '50.jpg', '327.jpg', '283.jpg', '107.jpg', '248.jpg', '349.jpg', '251.jpg', '278.jpg', '168.jpg', '256.jpg', '261.jpg', '288.jpg', '350.jpg', '133.jpg', '79.jpg', '160.jpg', '192.jpg', '48.jpg', '128.jpg', '81.jpg', '76.jpg', '102.jpg', '127.jpg', '111.jpg', '329.jpg', '299.jpg', '181.jpg', '289.jpg', '316.jpg', '345.jpg', '23.jpg', '91.jpg', '275.jpg', '319.jpg', '312.jpg', '137.jpg', '2.jpg', '134.jpg', '177.jpg', '63.jpg', '240.jpg', '99.jpg', '96.jpg', '98.jpg', '97.jpg', '95.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/297 [00:00<?, ?it/s]\u001b[A\n",
            "  6%|▌         | 17/297 [00:00<00:01, 166.53it/s]\u001b[A\n",
            " 11%|█▏        | 34/297 [00:00<00:01, 155.72it/s]\u001b[A\n",
            " 17%|█▋        | 50/297 [00:00<00:01, 149.28it/s]\u001b[A\n",
            " 22%|██▏       | 66/297 [00:00<00:01, 151.84it/s]\u001b[A\n",
            " 28%|██▊       | 82/297 [00:00<00:01, 153.96it/s]\u001b[A\n",
            " 33%|███▎      | 98/297 [00:00<00:01, 155.37it/s]\u001b[A\n",
            " 38%|███▊      | 114/297 [00:00<00:01, 155.54it/s]\u001b[A\n",
            " 44%|████▍     | 130/297 [00:00<00:01, 145.25it/s]\u001b[A\n",
            " 49%|████▉     | 147/297 [00:00<00:00, 150.70it/s]\u001b[A\n",
            " 55%|█████▍    | 163/297 [00:01<00:00, 148.33it/s]\u001b[A\n",
            " 61%|██████    | 180/297 [00:01<00:00, 152.95it/s]\u001b[A\n",
            " 66%|██████▋   | 197/297 [00:01<00:00, 155.82it/s]\u001b[A\n",
            " 72%|███████▏  | 213/297 [00:01<00:00, 149.53it/s]\u001b[A\n",
            " 77%|███████▋  | 230/297 [00:01<00:00, 155.00it/s]\u001b[A\n",
            " 83%|████████▎ | 246/297 [00:01<00:00, 145.15it/s]\u001b[A\n",
            " 88%|████████▊ | 261/297 [00:01<00:00, 138.46it/s]\u001b[A\n",
            " 94%|█████████▎| 278/297 [00:01<00:00, 146.97it/s]\u001b[A\n",
            "100%|██████████| 297/297 [00:01<00:00, 149.41it/s]\n",
            " 25%|██▌       | 1/4 [00:02<00:06,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Face Mask Detection/Datasets/surgical_mask\n",
            "['180-with-mask.jpg', '110-with-mask.jpg', '159-with-mask.jpg', '8-with-mask.jpg', '161-with-mask.jpg', '183-with-mask.jpg', '107-with-mask.jpg', '4-with-mask.jpg', '76-with-mask.jpg', '261-with-mask.jpg', '197-with-mask.jpg', '3-with-mask.jpg', '240-with-mask.jpg', '209-with-mask.jpg', '193-with-mask.jpg', '217-with-mask.jpg', '17-with-mask.jpg', '146-with-mask.jpg', '29-with-mask.jpg', '184-with-mask.jpg', '194-with-mask.jpg', '127-with-mask.jpg', '126-with-mask.jpg', '120-with-mask.jpg', '218-with-mask.jpg', '163-with-mask.jpg', '225-with-mask.jpg', '255-with-mask.jpg', '155-with-mask.jpg', '48-with-mask.jpg', '257-with-mask.jpg', '137-with-mask.jpg', '160-with-mask.jpg', '242-with-mask.jpg', '156-with-mask.jpg', '185-with-mask.jpg', '254-with-mask.jpg', '162-with-mask.jpg', '13-with-mask.jpg', '51-with-mask.jpg', '106-with-mask.jpg', '6-with-mask.jpg', '123-with-mask.jpg', '113-with-mask.jpg', '154-with-mask.jpg', '103-with-mask.jpg', '171-with-mask.jpg', '73-with-mask.jpg', '0-with-mask.jpg', '12-with-mask.jpg', '151-with-mask.jpg', '234-with-mask.jpg', '131-with-mask.jpg', '138-with-mask.jpg', '198-with-mask.jpg', '104-with-mask.jpg', '246-with-mask.jpg', '143-with-mask.jpg', '67-with-mask.jpg', '177-with-mask.jpg', '116-with-mask.jpg', '252-with-mask.jpg', '86-with-mask.jpg', '181-with-mask.jpg', '153-with-mask.jpg', '79-with-mask.jpg', '221-with-mask.jpg', '18-with-mask.jpg', '91-with-mask.jpg', '168-with-mask.jpg', '203-with-mask.jpg', '241-with-mask.jpg', '165-with-mask.jpg', '11-with-mask.jpg', '243-with-mask.jpg', '129-with-mask.jpg', '233-with-mask.jpg', '118-with-mask.jpg', '229-with-mask.jpg', '172-with-mask.jpg', '207-with-mask.jpg', '80-with-mask.jpg', '1-with-mask.jpg', '70-with-mask.jpg', '53-with-mask.jpg', '157-with-mask.jpg', '226-with-mask.jpg', '176-with-mask.jpg', '132-with-mask.jpg', '173-with-mask.jpg', '32-with-mask.jpg', '50-with-mask.jpg', '83-with-mask.jpg', '24-with-mask.jpg', '109-with-mask.jpg', '259-with-mask.jpg', '75-with-mask.jpg', '268-with-mask.jpg', '228-with-mask.jpg', '117-with-mask.jpg', '15-with-mask.jpg', '179-with-mask.jpg', '38-with-mask.jpg', '236-with-mask.jpg', '30-with-mask.jpg', '89-with-mask.jpg', '121-with-mask.jpg', '94-with-mask.jpg', '34-with-mask.jpg', '124-with-mask.jpg', '148-with-mask.jpg', '36-with-mask.jpg', '212-with-mask.jpg', '77-with-mask.jpg', '96-with-mask.jpg', '111-with-mask.jpg', '71-with-mask.jpg', '119-with-mask.jpg', '245-with-mask.jpg', '35-with-mask.jpg', '190-with-mask.jpg', '25-with-mask.jpg', '64-with-mask.jpg', '158-with-mask.jpg', '72-with-mask.jpg', '85-with-mask.jpg', '186-with-mask.jpg', '174-with-mask.jpg', '10-with-mask.jpg', '19-with-mask.jpg', '251-with-mask.jpg', '14-with-mask.jpg', '84-with-mask.jpg', '47-with-mask.jpg', '170-with-mask.jpg', '219-with-mask.jpg', '61-with-mask.jpg', '222-with-mask.jpg', '57-with-mask.jpg', '260-with-mask.jpg', '182-with-mask.jpg', '62-with-mask.jpg', '227-with-mask.jpg', '195-with-mask.jpg', '16-with-mask.jpg', '144-with-mask.jpg', '115-with-mask.jpg', '114-with-mask.jpg', '93-with-mask.jpg', '189-with-mask.jpg', '147-with-mask.jpg', '68-with-mask.jpg', '231-with-mask.jpg', '7-with-mask.jpg', '74-with-mask.jpg', '201-with-mask.jpg', '78-with-mask.jpg', '139-with-mask.jpg', '9-with-mask.jpg', '112-with-mask.jpg', '99-with-mask.jpg', '92-with-mask.jpg', '262-with-mask.jpg', '134-with-mask.jpg', '141-with-mask.jpg', '65-with-mask.jpg', '46-with-mask.jpg', '152-with-mask.jpg', '2-with-mask.jpg', '82-with-mask.jpg', '41-with-mask.jpg', '215-with-mask.jpg', '237-with-mask.jpg', '128-with-mask.jpg', '108-with-mask.jpg', '187-with-mask.jpg', '224-with-mask.jpg', '175-with-mask.jpg', '52-with-mask.jpg', '33-with-mask.jpg', '211-with-mask.jpg', '206-with-mask.jpg', '39-with-mask.jpg', '235-with-mask.jpg', '200-with-mask.jpg', '150-with-mask.jpg', '5-with-mask.jpg', '37-with-mask.jpg', '81-with-mask.jpg', '192-with-mask.jpg', '97-with-mask.jpg', '223-with-mask.jpg', '122-with-mask.jpg', '205-with-mask.jpg', '239-with-mask.jpg', '105-with-mask.jpg', '202-with-mask.jpg', '232-with-mask.jpg', '253-with-mask.jpg', '140-with-mask.jpg', '133-with-mask.jpg', '196-with-mask.jpg', '125-with-mask.jpg', '43-with-mask.jpg', '42-with-mask.jpg', '26-with-mask.jpg', '100-with-mask.jpg', '21-with-mask.jpg', '45-with-mask.jpg', '23-with-mask.jpg', '238-with-mask.jpg', '31-with-mask.jpg', '214-with-mask.jpg', '98-with-mask.jpg', '167-with-mask.jpg', '256-with-mask.jpg', '40-with-mask.jpg', '204-with-mask.jpg', '263-with-mask.jpg', '49-with-mask.jpg', '88-with-mask.jpg', '267-with-mask.jpg', '135-with-mask.jpg', '27-with-mask.jpg', '101-with-mask.jpg', '136-with-mask.jpg', '56-with-mask.jpg', '59-with-mask.jpg', '244-with-mask.jpg', '169-with-mask.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/230 [00:00<?, ?it/s]\u001b[A\n",
            "  8%|▊         | 19/230 [00:00<00:01, 181.11it/s]\u001b[A\n",
            " 17%|█▋        | 38/230 [00:00<00:01, 178.24it/s]\u001b[A\n",
            " 24%|██▍       | 56/230 [00:00<00:01, 155.79it/s]\u001b[A\n",
            " 33%|███▎      | 76/230 [00:00<00:00, 170.14it/s]\u001b[A\n",
            " 41%|████      | 94/230 [00:00<00:00, 168.68it/s]\u001b[A\n",
            " 49%|████▊     | 112/230 [00:00<00:00, 164.27it/s]\u001b[A\n",
            " 56%|█████▌    | 129/230 [00:00<00:00, 162.17it/s]\u001b[A\n",
            " 63%|██████▎   | 146/230 [00:00<00:00, 159.81it/s]\u001b[A\n",
            " 71%|███████   | 163/230 [00:01<00:00, 159.23it/s]\u001b[A\n",
            " 78%|███████▊  | 180/230 [00:01<00:00, 161.76it/s]\u001b[A\n",
            " 86%|████████▌ | 198/230 [00:01<00:00, 164.78it/s]\u001b[A\n",
            "100%|██████████| 230/230 [00:01<00:00, 165.92it/s]\n",
            " 50%|█████     | 2/4 [00:03<00:03,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Face Mask Detection/Datasets/cloth_mask\n",
            "['Masks may protect the wearer from the....jpg', 'CDC updates_ Double masking and best....jpg', 'Mask hygiene_ Experts say cloth masks....jpg', 'Dos and Don_ts of Mask Wearing.jpg', 'How Masks Went From Don_t-Wear to Must....jpg', 'What to look for in a cloth face mask_yythkg....jpg', 'Solutions to Common Face Mask....jpg', 'The best and worst choices for a cloth....jpg', 'Copper face masks to protect against....jpg', 'A woman wearing a face mask while....jpg', 'The science and psychology behind....jpg', '9 Types of Masks & Their Effectiveness... (1).jpg', 'Face masks reduce coronavirus....jpg', 'OLCreate_ An Introduction to....JPG', 'It_s winter. It_s cold. How do I deal ....webp', 'Yukoners sew homemade cloth masks to....webp', 'Wearing a mask is nasty and....jpg', 'Face Mask Sizing - Proper Cloth... (1).jpg', 'Coronavirus face masks_ an....jpg', 'Tips To Help Young Kids Wear Masks.jpg', 'Tips to Make Face Masks More....jpg', 'Cloth Mask vs. Surgical Mask_ The ....jpg', 'COVID-19 and masks_ Tips for families....jpg', 'How often you should wash cloth face....jpeg', 'Watch Dr. Fauci Demonstrate the Right ....jpg', 'Do cloth masks work_ Only if you....jpg', 'A doctor runs nearly 22 miles in a face_yyth....jpg', 'Should You Buy a Copper Fabric Face....jpg', 'Living with face masks_ How to stow....webp', 'To prevent COVID_ wear 2 masks or....jpg', 'How homemade cloth masks could help....jpg', 'The most common ways we_re wearing face....jpg', 'The CDC Now Recommends People Wear....png', 'WATCH_ Gov. Jared Polis asks all ....png', 'How to make a statement with your face mask (1).jpg', 'CDC Recommendation _ Cloth Face Masks....jpg', 'Boy wearing cloth mask against Covid 19....jpg', 'I urge people to wear cloth mask to....jpg', 'Dr. Fauci_ Double mask during Covid ....jpg', 'Is Your Fishing Neck Gaiter a Good Face....jpg', 'Amid face mask backlash_ police say....jpg', '27 Best Amazon Cloth Face Masks in 2021.jpg', 'Researchers Rank Face Mask By Effectiveness.jpg', 'COVID-19 masks FAQs_ How can cloth stop....jpg', 'Cloth masks in public might be here to....jpg', 'Wear masks to protect yourself from the....jpg', 'Residents should wear cloth face....jpg', '22_225 Person Wearing Cloth Mask Stock....jpg', 'Coronavirus India_ PM Wears Homemade....webp', 'The 19 Best Face Masks for Glasses....jpg', 'Is wearing a face mask causing your....jpg', 'The 10 best cloth face masks we tested....jpg', 'People are wearing colorful face masks....jpg', '19 Face Masks We Actually Like to Wear....jpg', 'I am choosing not to wear a mask_ Trump_yyth....jpg', 'CLOTH MASKS & COVID TRANSMISSION.png', '5 mistakes you_re probably making....jpg', 'Cloth versus surgical masks for....jpeg', 'FAQs About Wearing Masks - Cedar Rapids....jpg', 'The year_s top quotes_ _Wear a mask....jpg', '12_041 Woman Wearing Cloth Mask Stock....jpg', 'Portrait Asian Man Wearing Cloth Mask....jpg', 'Cute Cloth Masks Your Child May....png', 'Coronavirus FAQ_ Should I Wear A Mask....jpg', 'Young Woman Department Grocery Store....jpg', 'Non-medical masks can keep people with....jpg', 'Covid-19_ Are cloth masks still....jpg', 'Debunking Mask Myths_ Why It_s....jpg', 'Are Two Masks Better Than One_ What You....jpg', 'You asked_ Does a cloth face mask....jpg', '7 Myths and Facts About Face Masks....jpg', 'How to buy disposable face masks....jpg', 'What medical conditions prevent you....jpg', 'More Evidence for Masks—and Why They....jpeg', 'Jackson County recommends cloth face....jpg', 'Double-masking can increase your COVID....jpg', 'CDC Now Recommends All Citizens Wear....jpg', 'CDC recommends everyone wear cloth face....jpg', 'Cleaning fabric face masks_ How often....jpg', 'CDC says we all should wear face....jpg', '6 Questions You May Have About Cloth....jpg', 'We_ve found the most breathable fabric....jpg', 'Doctor explains how and when you should....jpg', 'Face Mask Sizing - Proper Cloth....jpg', 'How to clean your fabric face masks at home.jpeg', 'One Mid Adult Man Wearing A Home Made....jpg', 'CDC Recommending Cloth Masks_ Face... (1).jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]\u001b[A\n",
            "  6%|▌         | 5/87 [00:00<00:01, 46.18it/s]\u001b[A\n",
            " 11%|█▏        | 10/87 [00:00<00:01, 43.28it/s]\u001b[A\n",
            " 17%|█▋        | 15/87 [00:00<00:04, 16.70it/s]\u001b[A\n",
            " 22%|██▏       | 19/87 [00:00<00:03, 20.74it/s]\u001b[A\n",
            " 29%|██▊       | 25/87 [00:01<00:02, 25.49it/s]\u001b[A\n",
            " 37%|███▋      | 32/87 [00:01<00:01, 33.63it/s]\u001b[A\n",
            " 43%|████▎     | 37/87 [00:01<00:01, 35.72it/s]\u001b[A\n",
            " 48%|████▊     | 42/87 [00:01<00:01, 30.98it/s]\u001b[A\n",
            " 53%|█████▎    | 46/87 [00:01<00:01, 22.82it/s]\u001b[A\n",
            " 61%|██████    | 53/87 [00:01<00:01, 30.24it/s]\u001b[A\n",
            " 71%|███████▏  | 62/87 [00:02<00:00, 39.11it/s]\u001b[A\n",
            " 77%|███████▋  | 67/87 [00:02<00:00, 39.01it/s]\u001b[A\n",
            " 83%|████████▎ | 72/87 [00:02<00:00, 39.44it/s]\u001b[A\n",
            " 89%|████████▊ | 77/87 [00:02<00:00, 36.54it/s]\u001b[A\n",
            " 93%|█████████▎| 81/87 [00:02<00:00, 36.65it/s]\u001b[A\n",
            "100%|██████████| 87/87 [00:02<00:00, 31.37it/s]\n",
            " 75%|███████▌  | 3/4 [00:06<00:02,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Face Mask Detection/Datasets/ffp2_mask\n",
            "['Business Man Wearing Image & Photo....jpg', 'COVID-19 Young Woman Wearing KN95 FFP2... (1).jpg', 'Ffp2 Images_ Stock Photos & Vectors....jpg', 'Portrait of young elegant woman wearing....jpg', 'protection_ ffp mask - Stock Photo....jpg', 'Germany weighs up mandatory FFP2 masks....jpg', 'Breathable Cup FFP2 Mask Anti Dust Face....jpg', 'export of N-95_ FFP2 masks.webp', 'how to wear earloop ffp2 n95 face mask....jpg', 'ffp mask stock photos - OFFSET.jpg', 'COVID-19 Mobile Application Young Man....jpg', 'Portrait of red-haired woman wearing a....jpg', 'Young Man Wearing Ffp2 Mask To Protect... (1).jpg', 'Disposable Respirator Mask....jpg', '3_051 Ffp2 Mask Photos and Premium High....jpg', 'ffp2 mask stock photos - OFFSET.jpg', 'Madrid bans wearing FFP2 and FFP3 masks....jpg', 'Can you re-use FFP2 Masks_.jpeg', 'should medical-grade face masks be....jpg', 'Business Woman Wearing KN95 FFP2 Face....jpg', 'Corona office challenge_ business woman....jpg', 'Red-haired woman wearing a FFP2 face....jpg', '1.6 million free FFP2 masks for those ....jpg', 'Respirators - Chemstore UK.jpg', 'Professional Ffp2 Mask Against Virus....jpg', 'COVID-19 Young Woman Wearing KN95 FFP2....jpg', 'Young Man Wearing Ffp2 Mask To Protect....jpg', 'Grab The KN95 FFP2 Ear Face Mask (20Pcs....jpg', 'Blond woman wearing FFP2 mask and....jpg', 'Woman wearing FFP2 mask and using....jpg', 'Young Woman Wearing KN95 FFP2 Mask....jpg', 'Face masks_ What_s the difference....jpg', 'COVID-19 Pandemic Coronavirus Sick Man....jpg', 'masks over cloth face coverings....jpg', 'How long can we wear an FFP2 NR Mask_.jpg', 'blond woman wearing FFP2 mask... (2).jpg', 'COVID_ Germany debates making N95 masks... (1).jpg', 'blond woman wearing FFP2 mask....jpg', 'FFP2 face mask during the Covid-19....jpg', 'ffp2 mask - Backgrounds....jpg', 'Business Woman Wearing KN95 FFP2 Mask....jpg', '3_261 Ffp2 Photos - Free & Royalty-Free....jpg', 'KN95_FFP2 Respirator Mask – Anteo Medical.jpg', 'School woman wearing kn95 ffp2 mask....jpg', 'Is it time to upgrade your face mask....jpg', 'FFP2 mask requirement.jpg', 'FFP2 masks from SKYLOTEC_ Breathable....jpg', 'FFP2 masks from SKYLOTEC_ Breathable... (1).jpg', 'KN95_FFP2 Respirator Mask – Anteo Medical (2).jpg', '3_051 Ffp2 Mask Photos and Premium High... (1).jpg', 'COVID-19 Pandemic Coronavirus Man in....jpg', 'Traveler Woman Wearing KN95 FFP2 Face....jpg', 'dust mask - FFP2 mask uvex....jpg', 'When to wear a FFP2 face mask_ – Anteo_yythk....jpg', 'Why FFP2 Masks Are Perfect For Aviation....jpeg', 'Why FFP2 Masks Are Perfect For Aviation... (1).jpeg', 'COVID-19 Pandemic Coronavirus Young....jpg', 'Mistakes You_re Making With Face Masks....jpg', 'blond woman wearing FFP2 mask... (1).jpg', 'One million high-grade NHS masks....jpg', 'Blond woman wearing FFP2 mask and... (1).jpg', 'business woman wearing ffp2 kn95 face mask.jpg', 'Woman wearing FFP2 mask and using... (1).jpg', 'Young Woman Wearing KN95 FFP2 Mask... (1).jpg', 'Coronavirus _ Face Mask Types & Where....jpg', 'Face Mask At Train Station To Protect....jpg', 'face mask as Scottish Government....jpg', 'Safely Keep Your Mask Off....jpg', 'If You_re Layering These Masks_ the CDC....jpg', 'Woman Wearing Ffp2 Face Mask Shopping....jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/70 [00:00<?, ?it/s]\u001b[A\n",
            "  9%|▊         | 6/70 [00:00<00:01, 46.80it/s]\u001b[A\n",
            " 16%|█▌        | 11/70 [00:00<00:01, 48.00it/s]\u001b[A\n",
            " 26%|██▌       | 18/70 [00:00<00:01, 38.52it/s]\u001b[A\n",
            " 33%|███▎      | 23/70 [00:00<00:01, 26.77it/s]\u001b[A\n",
            " 39%|███▊      | 27/70 [00:00<00:01, 29.33it/s]\u001b[A\n",
            " 46%|████▌     | 32/70 [00:00<00:01, 32.64it/s]\u001b[A\n",
            " 56%|█████▌    | 39/70 [00:01<00:00, 41.31it/s]\u001b[A\n",
            " 63%|██████▎   | 44/70 [00:01<00:00, 32.47it/s]\u001b[A\n",
            " 69%|██████▊   | 48/70 [00:01<00:00, 31.96it/s]\u001b[A\n",
            " 74%|███████▍  | 52/70 [00:01<00:00, 26.44it/s]\u001b[A\n",
            " 80%|████████  | 56/70 [00:01<00:00, 26.84it/s]\u001b[A\n",
            " 89%|████████▊ | 62/70 [00:01<00:00, 33.27it/s]\u001b[A\n",
            "100%|██████████| 70/70 [00:02<00:00, 33.96it/s]\n",
            "100%|██████████| 4/4 [00:08<00:00,  2.08s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb7uCt33n19O"
      },
      "source": [
        "#Customized Dataset class to set and get the data.\n",
        "class FaceMaskDataset(Dataset):\n",
        "  #saving the data\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.transformation = Compose([\n",
        "                                   ToTensor(),\n",
        "                                   Resize((100,100))\n",
        "                                   ])\n",
        "  \n",
        "  def __getitem__(self, id):\n",
        "    return self.transformation(self.data[id][0]), torch.tensor(self.data[id][1])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.data.__len__()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujVIxWgER3ea"
      },
      "source": [
        "#CNN Architecture....\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv_layer = nn.Sequential(\n",
        "        #Layer 1\n",
        "        nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        #Layer 2\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    \n",
        "        #Layer 3\n",
        "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "    \n",
        "    self.linear_layers = nn.Sequential(\n",
        "        nn.Dropout(p=0.1),\n",
        "        nn.Linear(256 * 12 * 12, 128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(p=0.1),\n",
        "        nn.Linear(64,10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_layer(x)\n",
        "    #print(x.shape)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.linear_layers(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dRwxp23RXe6",
        "outputId": "72727065-eefa-4d74-e989-a06e23710112"
      },
      "source": [
        "#Data loading and Training\n",
        "data = np.load('data.npy', allow_pickle=True)\n",
        "#labels = np.load('labels.npy')\n",
        "\n",
        "training_data, testing_data = train_test_split(data, test_size = 0.3, random_state = 0)\n",
        "\n",
        "training_dataset = FaceMaskDataset(training_data)\n",
        "testing_dataset = FaceMaskDataset(testing_data)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=128)\n",
        "test_loader = DataLoader(testing_dataset, batch_size=128)\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "loss_criteria = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "training_accuracy_list = []\n",
        "training_loss_list = []\n",
        "\n",
        "for epoch in range(20):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    outputs = model(images)\n",
        "    \n",
        "    #Forward Pass\n",
        "    training_loss = loss_criteria(outputs, labels)\n",
        "    training_loss_list.append(training_loss.item)\n",
        "\n",
        "    #Backpropogation and Optimization\n",
        "    optimizer.zero_grad()\n",
        "    training_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #Training Accuracy\n",
        "    total = labels.size(0)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    training_accuracy_list.append(correct / total)\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "      print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "      .format(epoch + 1, 20, i + 1, total_step, training_loss.item(),\n",
        "      (correct / total) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n",
            "torch.Size([94, 256, 12, 12])\n",
            "torch.Size([128, 256, 12, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIn1x0-9XiWV"
      },
      "source": [
        "#Confusion Matrix - Accuracy, f-measure, recall and precision\n",
        "def generate_matrix(model, title, data_loader):\n",
        "  model.eval()\n",
        "  prediction_list = []\n",
        "  accurate_list = []\n",
        "  with torch.no_grad():\n",
        "    for images, labels in data_loader:\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(model(images), 1)\n",
        "      prediction_list.extend(predicted.detach().cpu().numpy())\n",
        "      accurate_list.extend(labels.detach().cpu().numpy())\n",
        "  \n",
        "  print(\"{} Classification Report: \".format(title))\n",
        "  print(classification_report(prediction_list, accurate_list))\n",
        "  plt.figure()\n",
        "  confusion_matrix_instance = confusion_matrix(accurate_list, prediction_list)\n",
        "  for (x_cordinate, y_cordinate), val in np.ndenumerate(confusion_matrix_instance):\n",
        "        plt.text(x_cordinate, y_cordinate, val, ha='center', va='center')\n",
        "  plt.title('{} Confusion matrix'.format(title))\n",
        "  plt.ylabel('Actual labels')\n",
        "  plt.xlabel('Predicted labels')\n",
        "  randomized_val = np.arange(len(label))\n",
        "  plt.xticks(randomized_val, classes, rotation=60)\n",
        "  plt.yticks(randomized_val, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNNUdTAtwXP3",
        "outputId": "cbb1a00f-5ceb-423e-8459-8f3f3c482d19"
      },
      "source": [
        "generate_matrix(model, \"training\", train_loader)\n",
        "generate_matrix(model, \"testing\", test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       206\n",
            "           1       1.00      1.00      1.00       160\n",
            "           2       1.00      1.00      1.00        63\n",
            "           3       1.00      1.00      1.00        49\n",
            "\n",
            "    accuracy                           1.00       478\n",
            "   macro avg       1.00      1.00      1.00       478\n",
            "weighted avg       1.00      1.00      1.00       478\n",
            "\n",
            "testing Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.90        90\n",
            "           1       0.93      0.89      0.91        73\n",
            "           2       0.50      0.57      0.53        21\n",
            "           3       0.52      0.50      0.51        22\n",
            "\n",
            "    accuracy                           0.82       206\n",
            "   macro avg       0.71      0.72      0.71       206\n",
            "weighted avg       0.82      0.82      0.82       206\n",
            "\n"
          ]
        }
      ]
    }
  ]
}