# -*- coding: utf-8 -*-
"""Face_mask_detection_part_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h6Jqft6lQfAiTiSfJrCwM3BeUcnCpk3_
"""

#All the required libraries are imported here
from google.colab import drive
import os
import cv2
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
from tqdm import tqdm
import torch.nn as nn
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
from torch.utils.data.dataset import Dataset
from torchvision.transforms import ToPILImage, Compose, ToTensor, Resize, Normalize
from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import classification_report, confusion_matrix
from torchvision import transforms
from PIL import Image
import seaborn as sns
from torch.utils.data.dataset import Dataset, Subset
from sklearn.model_selection import KFold

#Setting the path up for the dataset. Dataset is in Goole Drive
drive.mount('/content/drive', force_remount=True)
dir_path = "/content/drive/My Drive/Face Mask Detection/Datasets"
save_dir = "/content/drive/My Drive/Face Mask Detection/loaded_images.npy"
model_dir = "/content/drive/My Drive/Face Mask Detection/saved_model"
sample_image_path = "/content/drive/My Drive/Face Mask Detection/test"

classes = os.listdir(dir_path)
print(classes)

label = [i for i in range(len(classes))]
print(label)


label_dict = dict(zip(classes,label))
print(label_dict)

category_label = dict(zip(label, classes))
print(category_label)

data = []
#labels = []
for label in tqdm(classes):
  data_path = os.path.join(dir_path, label)
  print("Data Path", data_path)
  image_names = os.listdir(data_path)
  print("Image Name", image_names)
  for image in tqdm(image_names):
    image_path = os.path.join(data_path, image)
    images = cv2.imread(image_path) 
    try:
      imag = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)
      img = cv2.resize(imag, (100,100))
        
      data.append((img, label_dict[label]))
      
    except Exception as e:
      print(e)

np.random.shuffle(data)  
np.save(save_dir, data)

#Customized Dataset class to set and get the data.
class FaceMaskDataset(Dataset):
  #saving the data
  def __init__(self, data):
    self.data = data
    self.transformation = transforms.Compose([
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
                                   transforms.Resize((100,100))
                                   ])
  
  def __getitem__(self, id):
    return self.transformation(self.data[id][0]), torch.tensor(self.data[id][1])
  
  def __len__(self):
    return self.data.__len__()

"""
#This will load the saved data and then split it into two parts and then load the data 
#using DataLoader() method with some batch_size.
def data_loader(save_dir):
  data = np.load(save_dir, allow_pickle=True)

  training_data, testing_data = train_test_split(data, test_size = 0.3, random_state = 0)

  training_dataset = FaceMaskDataset(training_data)
  testing_dataset = FaceMaskDataset(testing_data)

  train_loader = DataLoader(training_dataset, batch_size=32)
  test_loader = DataLoader(testing_dataset, batch_size=32)

  return train_loader, test_loader
  """



def dataset_loader(save_dir):
  data = np.load(save_dir, allow_pickle=True)
  loaded_dataset = FaceMaskDataset(data)
  return loaded_dataset

loaded_dataset = dataset_loader(save_dir)
print(len(loaded_dataset))
kfold = KFold(n_splits=10, shuffle=True, random_state=None)
fold_value = 1
for training_id, testing_id in kfold.split(loaded_dataset):
  print("Fold Number:", fold_value)

  training_dataset = Subset(loaded_dataset, training_id)
  testing_dataset = Subset(loaded_dataset, testing_id)
  train_loader = DataLoader(training_dataset, batch_size=64, num_workers=0, shuffle=True)
  test_loader = DataLoader(testing_dataset, batch_size=64, num_workers=0, shuffle=True)
  model = model_trainer(train_loader, test_loader, 10)
  model_name = "Model_Number_" + str(fold_value)
  testing_model(model, model_name, test_loader)
  fold_value+=1

#Confusion Matrix - Accuracy, f-measure, recall and precision and also plotting confusion Matrix
def testing_model(model, title, data_loader):
  model.eval()
  prediction_list = []
  accurate_list = []
  with torch.no_grad():
    for images, labels in data_loader:
      outputs = model(images)
      _, predicted = torch.max(model(images), 1)
      prediction_list.extend(predicted.detach().cpu().numpy())
      accurate_list.extend(labels.detach().cpu().numpy())
  print(prediction_list)
  print(accurate_list)
  print("{} Classification Report: ".format(title))
  print(classification_report(prediction_list, accurate_list))

#train_loader, test_loader = data_loader(save_dir)

#CNN Architecture to train the model.
class CNN(nn.Module):
  def __init__(self):
    super(CNN, self).__init__()
    self.conv_layer = nn.Sequential(
        #Layer 1
        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(64),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Dropout2d(p=0.02),
        
        #Layer 2
        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(128),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Dropout2d(p=0.02),
        
        #Layer 3
        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(256),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2),
        nn.Dropout2d(p=0.02),
        
        #Layer 4
        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),
        nn.BatchNorm2d(512),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2),
    
        nn.Dropout2d(p=0.05),
    )
    
    #Fully Connected Layer
    self.linear_layers = nn.Sequential(
        nn.Dropout(p=0.1),
        nn.Linear(512 * 6 * 6, 128),
        nn.ReLU(inplace=True),
        nn.Linear(128, 64),
        nn.ReLU(inplace=True),
        nn.Dropout(p=0.1),
        nn.Linear(64,4)
    )

  def forward(self, x):
    x = self.conv_layer(x)
    #print(x.shape)
    x = x.view(x.size(0), -1)
    x = self.linear_layers(x)
    return x

#This method will train the dataset according to the specified epoch number.
def model_trainer(train_loader, test_loader, epoch_number):
  model = CNN()

  loss_criteria = nn.CrossEntropyLoss()
  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)

  total_step = len(train_loader)
  training_accuracy_list = []
  training_loss_list = []

  for epoch in range(epoch_number):
    for i, (images, labels) in enumerate(train_loader):
      outputs = model(images)

      #Forward Pass
      training_loss = loss_criteria(outputs, labels)
      training_loss_list.append(training_loss.item())

      #Backpropogation and Optimization
      optimizer.zero_grad()
      training_loss.backward()
      optimizer.step()

      #Training Accuracy
      total = labels.size(0)
      _, predicted = torch.max(outputs.data, 1)
      correct = (predicted == labels).sum().item()
      training_accuracy_list.append(correct / total)

    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'
        .format(epoch + 1, epoch_number, training_loss.item(),
        (correct / total) * 100))

  return model

model = model_trainer(train_loader, test_loader, epoch_number=10)

#This method will save the model onto a pre-specified path.
def save_model(model, model_name, model_save_dir):
  torch.save(model.state_dict(), "{}/{}".format(model_save_dir, model_name))

model_name = "COMP6721-AI-Project-1"
save_model(model, model_name, model_dir)

def load_data(data, path, label):
  
  #labels = []
  image_names = os.listdir(path)
  print("Image Name", image_names)
  print("Image Labels", label)
  for image in tqdm(image_names):
    image_path = os.path.join(path, image)
    images = cv2.imread(image_path) 
    try:
      imag = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)
      img = cv2.resize(imag, (100,100))
          
      data.append((img, label))
        
    except Exception as e:
      print(e)
  return data

#Entering some drive location of testing dataset
cloth_mask_male_dir = "/content/drive/My Drive/Face Mask Detection/test_data/gender/cloth_mask_male"
cloth_mask_female_dir = "/content/drive/My Drive/Face Mask Detection/test_data/gender/cloth_mask_female"
cloth_mask_child_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/cloth_mask_child"
cloth_mask_young_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/cloth_mask_young"
cloth_mask_old_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/cloth_mask_old"

#Getting surgical mask data
surgical_mask_male_dir = "/content/drive/My Drive/Face Mask Detection/test_data/gender/surgical_mask_male"
surgical_mask_female_dir = "/content/drive/My Drive/Face Mask Detection/test_data/gender/surgical_mask_female"
surgical_mask_child_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/surgical_mask_child"
surgical_mask_young_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/surgical_mask_young"
surgical_mask_old_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/surgical_mask_old"

#Getting Without mask data
without_mask_male_dir = "/content/drive/My Drive/Face Mask Detection/test_data/gender/without_mask_male"
without_mask_female_dir = "/content/drive/My Drive/Face Mask Detection/test_data/gender/without_mask_female"
without_mask_child_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/without_mask_child"
without_mask_young_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/without_mask_young"
without_mask_old_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/without_mask_old"

#Getting ffp2 mask data
ffp2_mask_male_dir = "/content/drive/My Drive/Face Mask Detection/test_data/gender/ffp2_mask_male"
ffp2_mask_female_dir = "/content/drive/My Drive/Face Mask Detection/test_data/gender/ffp2_mask_female"
ffp2_mask_child_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/ffp2_mask_child"
ffp2_mask_young_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/ffp2_mask_young"
ffp2_mask_old_dir = "/content/drive/My Drive/Face Mask Detection/test_data/age/ffp2_mask_old"

#Getting testing dataset
cloth_testing_dataset = "/content/drive/My Drive/Face Mask Detection/testing_dataset/cloth_mask"
ffp2_testing_dataset = "/content/drive/My Drive/Face Mask Detection/testing_dataset/ffp2_mask"
surgical_testing_dataset = "/content/drive/My Drive/Face Mask Detection/testing_dataset/surgical_mask"
without_mask_testing_dataset = "/content/drive/My Drive/Face Mask Detection/testing_dataset/without_mask"

print("-----------Cloth Mask worn by Male-----------")
mask_male_data = []
mask_male_data = load_data(mask_male_data, cloth_mask_male_dir, 0)
mask_male_data = load_data(mask_male_data, ffp2_mask_male_dir, 1)
mask_male_data = load_data(mask_male_data, surgical_mask_male_dir, 2)
mask_male_data = load_data(mask_male_data, without_mask_male_dir, 3)

print("-----------Cloth Mask worn by Female-----------")
mask_female_data = []
mask_female_data = load_data(mask_female_data, cloth_mask_female_dir, 0)
mask_female_data = load_data(mask_female_data, ffp2_mask_female_dir, 1)
mask_female_data = load_data(mask_female_data, surgical_mask_female_dir, 2)
mask_female_data = load_data(mask_female_data, without_mask_female_dir, 3)

print("-----------Cloth Mask worn by Child-----------")
mask_child_data = []
mask_child_data = load_data(mask_child_data, cloth_mask_child_dir, 0)
mask_child_data = load_data(mask_child_data, ffp2_mask_child_dir, 1)
mask_child_data = load_data(mask_child_data, surgical_mask_child_dir, 2)
mask_child_data = load_data(mask_child_data, without_mask_child_dir, 3)

print("-----------Cloth Mask worn by Young-----------")
mask_young_data = []
mask_young_data = load_data(mask_young_data, cloth_mask_young_dir, 0)
mask_young_data = load_data(mask_young_data, ffp2_mask_young_dir, 1)
mask_young_data = load_data(mask_young_data, surgical_mask_young_dir, 2)
mask_young_data = load_data(mask_young_data, without_mask_young_dir, 3)

print("-----------Cloth Mask worn by Old-----------")
mask_old_data = []
mask_old_data = load_data(mask_old_data, cloth_mask_old_dir, 0)
mask_old_data = load_data(mask_old_data, ffp2_mask_old_dir, 1)
mask_old_data = load_data(mask_old_data, surgical_mask_old_dir, 2)
mask_old_data = load_data(mask_old_data, without_mask_old_dir, 3)

def testing_dataset_loader(data):
  print("Shuffling Data:")
  np.random.shuffle(data)

  print("Loading Data:")
  #data = np.load(dir, allow_pickle=True)
  loaded_dataset = FaceMaskDataset(data)
  #print(loaded_dataset)
  return loaded_dataset

print("----------Loading mask worn by Female----------")
mask_female = testing_dataset_loader(mask_female_data)
print("----------Loading mask worn by Male----------")
mask_male = testing_dataset_loader(mask_male_data)
print("----------Loading mask worn by Child----------")
mask_child = testing_dataset_loader(mask_child_data)
print("----------Loading mask worn by Young----------")
mask_young = testing_dataset_loader(mask_young_data)
print("----------Loading mask worn by Old----------")
mask_old = testing_dataset_loader(mask_old_data)

def generate_testing_matrix(model, title, data_loader):
  #print(len(data_loader))
  model.eval()
  prediction_list = []
  accurate_list = []
  with torch.no_grad():
    for images, labels in data_loader:
      #print(len(images))
      image = images.unsqueeze(0)
      #print(len(image))
      #print(labels.detach().cpu().numpy())
      outputs = model(image)
      _, predicted = torch.max(model(image), 1)
      prediction_list.extend(predicted.detach().cpu().numpy())
      accurate_list.extend([labels.detach().cpu().numpy()])
     
    
  print("{} Classification Report: ".format(title))
  print(classification_report(prediction_list, accurate_list))
  print("{} Confusion Matrix: ".format(title))
  
  confusion_matrix_data = confusion_matrix(accurate_list, prediction_list)
 
  #Plotting confusion matrix
  conf_matrix = sns.heatmap(confusion_matrix_data, annot=True, fmt='g' )

  conf_matrix.set_title('Confusion Matrix with labels!!');
  conf_matrix.set_xlabel('Predicted Categories')
  conf_matrix.set_ylabel('Actual Categories');
  
  
  conf_matrix.xaxis.set_ticklabels(["Cloth Mask", "FFP2 Mask", "Surgical Mask", "Without Mask"])
  conf_matrix.yaxis.set_ticklabels(["Cloth Mask", "FFP2 Mask", "Surgical Mask", "Without Mask"])

  plt.setp(conf_matrix.get_xticklabels(), rotation=45, ha="right",
         rotation_mode="anchor")
  plt.setp(conf_matrix.get_yticklabels(), rotation=60, ha="right",
         rotation_mode="anchor")
  
  plt.show()

print("------------Generate Matrix of Male------------")
generate_testing_matrix(model, "Mask Male Image", mask_male)
print("------------Generate Matrix of Female------------")
generate_testing_matrix(model, "Mask Male Image", mask_female)
print("------------Generate Matrix of Child------------")
generate_testing_matrix(model, "Mask Child Image", mask_child)
print("------------Generate Matrix of Young/Adult------------")
generate_testing_matrix(model, "Mask Young Image", mask_young)
print("------------Generate Matrix of Old------------")
generate_testing_matrix(model, "Mask Old Image", mask_old)


print("Testing already seperated dataset from the training.")
test_data = []
test_data = load_data(test_data, cloth_testing_dataset, 0)
test_data = load_data(test_data, ffp2_testing_dataset, 1)
test_data = load_data(test_data, surgical_testing_dataset, 2)
test_data = load_data(test_data, without_mask_testing_dataset, 3)

print("Loading the dataset:")
test_dataset = testing_dataset_loader(test_data)

print("Generating Classification and Confusion Matrix: ")
generate_testing_matrix(model, "Testing Dataset", test_dataset)

#Confusion Matrix - Accuracy, f-measure, recall and precision and also plotting confusion Matrix
def generate_matrix(model, title, data_loader, classes):
  model.eval()
  prediction_list = []
  accurate_list = []
  with torch.no_grad():
    for images, labels in data_loader:
      outputs = model(images)
      _, predicted = torch.max(model(images), 1)
      prediction_list.extend(predicted.detach().cpu().numpy())
      accurate_list.extend(labels.detach().cpu().numpy())
  print(prediction_list)
  print(accurate_list)
  print("{} Classification Report: ".format(title))
  print(classification_report(prediction_list, accurate_list))
  print("{} Confusion Matrix: ".format(title))
  
  confusion_matrix_data = confusion_matrix(accurate_list, prediction_list)
 
  #Plotting confusion matrix
  conf_matrix = sns.heatmap(confusion_matrix_data, annot=True, fmt='g' )

  conf_matrix.set_title('Confusion Matrix with labels!!');
  conf_matrix.set_xlabel('Predicted Categories')
  conf_matrix.set_ylabel('Actual Categories');

  print(label_dict)
  print(label_dict.get(0))
  
  
  conf_matrix.xaxis.set_ticklabels(["Cloth Mask", "FFP2 Mask", "Surgical Mask", "Without Mask"])
  conf_matrix.yaxis.set_ticklabels(["Cloth Mask", "FFP2 Mask", "Surgical Mask", "Without Mask"])

  plt.setp(conf_matrix.get_xticklabels(), rotation=45, ha="right",
         rotation_mode="anchor")
  plt.setp(conf_matrix.get_yticklabels(), rotation=60, ha="right",
         rotation_mode="anchor")
  
  plt.show()

generate_matrix(model, "Training", train_loader, classes)
generate_matrix(model, "Testing", test_loader, classes)